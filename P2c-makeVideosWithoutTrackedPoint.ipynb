{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open cv2 version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "print(\"open cv2 version: %s\" % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(vidPath, firstFrame, lastFrame):\n",
    "    '''\n",
    "    Reads frames from video and stores as a list\n",
    "    \n",
    "    Parameters: \n",
    "    vidPath (string): Path to video\n",
    "    \n",
    "    Returns: \n",
    "    list of images\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(vidPath)\n",
    "    length = np.arange(start, stop)\n",
    "    print(len(length)) \n",
    "    imgs = []\n",
    "    for ff in length:\n",
    "        cap.set(1,ff)\n",
    "        ret, frame = cap.read()\n",
    "        if np.mod(ff, 100) == 0:\n",
    "            print(ff) # prints progress in 50 frames\n",
    "\n",
    "            # convert to grey\n",
    "            #img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        imgs.append(frame)\n",
    "#         print(\"length of imgs: %s\" % len(imgs))\n",
    "            \n",
    "    cap.release()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust gamma, if your vid is too dark\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give path to videofiles\n",
    "vidpath = r\"G:\\My Drive\\Mahad\\Light Level Experiments\\Videos Used for Analysis/\"\n",
    "export_path = r'./dataFolder/Output/Proboscis/TrackedVideos/'\n",
    "\n",
    "# the Ref provides the start and stop frames\n",
    "path_frames = glob.glob(r\"./dataFolders/Output/Step5_v3/\" + '*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videosTobeMade = pd.read_csv('./dataFolders/Output/Proboscis/ListOFVideosManuallyTracked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videosTobeMade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "videosTobeMade = pd.DataFrame()\n",
    "videosTobeMade.loc[0, 'name'] = 'L50_c-3_m9_FirstVisit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>L50_c-3_m9_FirstVisit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name\n",
       "0  L50_c-3_m9_FirstVisit"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# videosTobeMade = pd.DataFrame()\n",
    "videosTobeMade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145118 648 488 30.0\n",
      "1817\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "length of section you want to read: 1817\n",
      "length of the image list: 1817\n",
      "0  of  1817\n",
      "100  of  1817\n",
      "200  of  1817\n",
      "300  of  1817\n",
      "400  of  1817\n",
      "500  of  1817\n",
      "600  of  1817\n",
      "700  of  1817\n",
      "800  of  1817\n",
      "900  of  1817\n",
      "1000  of  1817\n",
      "1100  of  1817\n",
      "1200  of  1817\n",
      "1300  of  1817\n",
      "1400  of  1817\n",
      "1500  of  1817\n",
      "1600  of  1817\n",
      "1700  of  1817\n",
      "1800  of  1817\n",
      "./dataFolders/Output/Proboscis/ManualTracking\\tmpImgs\n"
     ]
    }
   ],
   "source": [
    "visitnum = ['FirstVisit', 'Lastvisit']\n",
    "\n",
    "for name in videosTobeMade.name:\n",
    "    mothID = name.split('_')[0] + '_' + name.split('_')[1] + '_' + name.split('_')[2]\n",
    "\n",
    "    # get the video section\n",
    "    videoPath = vidpath + mothID + '.mp4'\n",
    "    frame_ref = [f for f in path_frames if mothID + '_' in f][0]\n",
    "    file = pd.read_csv(frame_ref)\n",
    "\n",
    "    visit = name.split('_')[3]\n",
    "    if visit == 'FirstVisit':\n",
    "        row = 0\n",
    "    else:\n",
    "        row = -1\n",
    "\n",
    "    select = file.iloc[row, :]\n",
    "    start = int(select['In_Frame'] + 1)\n",
    "    stop = int(select['Out_Frame'])\n",
    "\n",
    "    # get vid info\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(length, width, height, fps)\n",
    "    # load images\n",
    "    imList = load_imgs(videoPath, start, stop)\n",
    "    cap.release()\n",
    "\n",
    "    print(\"length of section you want to read: %s\" % int(stop - start))\n",
    "    print(\"length of the image list: %s\" % len(imList))\n",
    "    vidLen = len(imList)\n",
    "\n",
    "    # make directory to store images\n",
    "    tempImgDirectory = os.path.join(os.path.dirname(r\"./dataFolders/Output/Proboscis/ManualTracking/\"), \n",
    "                                    \"tmpImgs\")\n",
    "    if not os.path.exists(tempImgDirectory):\n",
    "        os.mkdir(tempImgDirectory)\n",
    "\n",
    "    #######################################################\n",
    "    outputImgs = []\n",
    "    for frameNum in np.arange(0, vidLen):\n",
    "\n",
    "        # adjust gamma\n",
    "        image = adjust_gamma(imList[frameNum], 1.5)           \n",
    "        # save img\n",
    "        cv2.imwrite(os.path.join(tempImgDirectory, str(frameNum).zfill(4) + \".png\"),\n",
    "                   image)           \n",
    "        if np.mod(frameNum, 100) == 0:\n",
    "            print(frameNum, \" of \", vidLen)\n",
    "    #################################################################################\n",
    "\n",
    "    # convert images to video with ffmpeg\n",
    "    returnDir = os.getcwd()\n",
    "    os.chdir(tempImgDirectory)\n",
    "    print(tempImgDirectory)\n",
    "\n",
    "    # use ffmpeg to convert directory to video\n",
    "    # -r is output frame rate\n",
    "    os.system('ffmpeg -start_number 0 -r 20 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -pix_fmt yuv420p -y outputVid.mp4')\n",
    "\n",
    "    nameofVideo = r'./' + name + '.mp4'\n",
    "    os.rename(r'./outputVid.mp4', nameofVideo)\n",
    "    os.chdir(returnDir)\n",
    "\n",
    "    # delete images from directory\n",
    "    delFiles = [f for f in os.listdir(tempImgDirectory) if f.endswith(\"png\")]\n",
    "    dlfs = [os.remove(os.path.join(tempImgDirectory, delFiles[ii])) for ii in range(len(delFiles))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
