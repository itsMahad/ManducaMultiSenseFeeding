{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "# Defining all the functions I use here\n",
    "\n",
    "def erodeImage(image):\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "    erosion = cv2.erode(image, kernel, iterations=1)\n",
    "    return erosion\n",
    "\n",
    "def dilateImage(image):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilate = cv2.dilate(image,kernel, iterations=1)\n",
    "    return dilate\n",
    "\n",
    "# removing high pixels - input single image\n",
    "\n",
    "#def removeHighPixel(image):\n",
    "#    im = np.copy(image)\n",
    "#    im[im > 220] = 0\n",
    "#    return im\n",
    "\n",
    "\n",
    "# calculate total number of pixels above threshold\n",
    "\n",
    "def pixelThreshold(image):\n",
    "    image = np.asarray(image)\n",
    "    val = image[image > 5]\n",
    "    count = len(val)\n",
    "    return count\n",
    "\n",
    "\n",
    "# calculate centroid, Num of pixels > threshold for a single frame\n",
    "\n",
    "def MotionParameters(diff_image):\n",
    "#    high_pix = removeHighPixel(diff_image)\n",
    "    eroded = erodeImage(diff_image)\n",
    "    dilated = dilateImage(eroded)\n",
    "    pixel = pixelThreshold(dilated)\n",
    "\n",
    "    mask = cv2.inRange(dilated, 5, 200)   # extract contour and the centroid of the biggest contour\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    _, contours, hierarchy = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    if (len(contours) >= 1) & np.any(areas):\n",
    "\n",
    "        max_index = np.argmax(areas)    # Find the index of the largest contour\n",
    "        contour_basic = contours[max_index]\n",
    "        contour_hull = cv2.convexHull(contour_basic)\n",
    "\n",
    "        M = cv2.moments(contour_basic)\n",
    "        centroid_basic = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "        M_hull = cv2.moments(contour_hull)\n",
    "        centroid_hull = (int(M_hull[\"m10\"] / M_hull[\"m00\"]), int(M_hull[\"m01\"] / M_hull[\"m00\"]))\n",
    "\n",
    "    else:\n",
    "        centroid_basic = (np.nan, np.nan)\n",
    "#        contour_basic = ()\n",
    "        centroid_hull = (np.nan, np.nan)\n",
    "#        contour_hull = ()\n",
    "\n",
    "    return pixel, centroid_basic, centroid_hull\n",
    "\n",
    "\n",
    "# make a list of all mp4 files\n",
    "def listOfVideos(path): \n",
    "#path = 'C:/Users/tanvid2/Documents/FLowerMorph-LearningExpt/Videos'\n",
    "# path = 'C:\\\\Users\\\\tanvid2\\\\Documents\\\\PyCharm Projects\\\\videoAnalysis\\\\testLoopVideos'\n",
    "    video_files = [(os.path.join(root, name), name[0:-4])\n",
    "                   for root, dirs, files in os.walk(path)\n",
    "                   for name in files\n",
    "                   if name.endswith('.mp4')]\n",
    "    return video_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 11 15:53:30 2019\tL0.1_c-3_m45 loaded\n",
      "analyzing 183848 frames for L0.1_c-3_m45\n",
      "L0.1_c-3_m45 took 1507.6849999427795 seconds\n",
      "Mon Nov 11 16:18:38 2019\tL0.1_c-3_m46 loaded\n",
      "analyzing 49883 frames for L0.1_c-3_m46\n",
      "L0.1_c-3_m46 took 407.59600019454956 seconds\n",
      "Mon Nov 11 16:25:26 2019\tL0.1_c-3_m47 loaded\n",
      "analyzing 162060 frames for L0.1_c-3_m47\n",
      "L0.1_c-3_m47 took 1402.0280003547668 seconds\n",
      "Mon Nov 11 16:48:48 2019\tL0.1_c-3_m48 loaded\n",
      "analyzing 112784 frames for L0.1_c-3_m48\n",
      "L0.1_c-3_m48 took 897.4779996871948 seconds\n",
      "Mon Nov 11 17:03:45 2019\tL0.1_c-3_m49 loaded\n",
      "analyzing 164177 frames for L0.1_c-3_m49\n",
      "L0.1_c-3_m49 took 1371.5439999103546 seconds\n",
      "Mon Nov 11 17:26:37 2019\tL0.1_c-3_m50 loaded\n",
      "analyzing 67497 frames for L0.1_c-3_m50\n",
      "L0.1_c-3_m50 took 547.3869998455048 seconds\n",
      "Mon Nov 11 17:35:44 2019\tL0.1_c-3_m54 loaded\n",
      "analyzing 213982 frames for L0.1_c-3_m54\n",
      "L0.1_c-3_m54 took 1817.6439998149872 seconds\n",
      "Mon Nov 11 18:06:02 2019\tL0.1_c-3_m57 loaded\n",
      "analyzing 204076 frames for L0.1_c-3_m57\n",
      "L0.1_c-3_m57 took 1680.1319999694824 seconds\n",
      "Mon Nov 11 18:34:02 2019\tL50_c-3_m49 loaded\n",
      "analyzing 125854 frames for L50_c-3_m49\n",
      "L50_c-3_m49 took 1028.0759999752045 seconds\n",
      "Mon Nov 11 18:51:10 2019\tL50_c-3_m50 loaded\n",
      "analyzing 111562 frames for L50_c-3_m50\n",
      "L50_c-3_m50 took 843.3199999332428 seconds\n",
      "Mon Nov 11 19:05:13 2019\tL50_c-3_m51 loaded\n",
      "analyzing 82347 frames for L50_c-3_m51\n",
      "L50_c-3_m51 took 649.1870000362396 seconds\n",
      "Mon Nov 11 19:16:02 2019\tL50_c-3_m58 loaded\n",
      "analyzing 83322 frames for L50_c-3_m58\n",
      "L50_c-3_m58 took 647.5329999923706 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run analysis through all files\n",
    "\n",
    "#give path to videofiles\n",
    "path = r\"C:\\Users\\Daniellab\\Desktop\\Light_level_videos_second_batch\\Videos\\November_2019_Batch\"    \n",
    "video_files = listOfVideos(path)\n",
    "for file in video_files:\n",
    "    path = file[0]\n",
    "    name = file[1]\n",
    "    \n",
    "    with open('LogFile.txt', 'a') as log_text:\n",
    "        log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' loaded' + '\\n')\n",
    "    print(str(time.asctime()) + '\\t' + file[1] + ' loaded')\n",
    "\n",
    "    t0 = time.time()     # log the start time\n",
    "\n",
    "    # declare all variables\n",
    "    num_pixel = []\n",
    "    centroid_basic_x = []\n",
    "    centroid_basic_y = []\n",
    "    centroid_hull_x = []\n",
    "    centroid_hull_y = []\n",
    "#    contour_basic = []\n",
    "#    contour_hull = []\n",
    "\n",
    "    cam = cv2.VideoCapture(path)  # load video as object\n",
    "\n",
    "    back_frame = 0  # calculate background to subtract from frame\n",
    "    cam.set(1, back_frame)\n",
    "    ret, f = cam.read(1)  # Read the image at the first frame\n",
    "    if not ret:\n",
    "        with open('LogFile.txt', 'a') as log_text:\n",
    "            log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' first image not read' + '\\n')\n",
    "        print(str(time.asctime()) + '\\t' + name + ' image not read')\n",
    "    background = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # loop through all frames of the video\n",
    "    total_frame = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_seq = list(range(0, total_frame))\n",
    "\n",
    "    print('analyzing ' + str(total_frame) + ' frames for ' + name)\n",
    "\n",
    "    for frame in frame_seq:\n",
    "        cam.set(1, frame)  # start processing the current frame\n",
    "        ret, f = cam.read(1)  # Read the image at that frame\n",
    "        if not ret:\n",
    "            with open('LogFile.txt', 'a') as log_text:\n",
    "                log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' frame ' + frame + ' not read' + '\\n')\n",
    "            print(str(time.asctime()) + '\\t' + name + ' frame ' + frame + ' not read')\n",
    "        \n",
    "        \n",
    "        img = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        diff_im = cv2.subtract(img, background)\n",
    "        \n",
    "        pixel, cent_b, cent_hull = MotionParameters(diff_im)\n",
    "        num_pixel.append(pixel)\n",
    "        centroid_basic_x.append(cent_b[0])\n",
    "        centroid_basic_y.append(cent_b[1])\n",
    "        centroid_hull_x.append(cent_hull[0])\n",
    "        centroid_hull_y.append(cent_hull[1])\n",
    "#        contour_basic.append(cont_b)\n",
    "#        contour_hull.append(cont_hull)\n",
    "    \n",
    "    gauss = signal.gaussian(3,3)\n",
    "    x_gauss = signal.convolve(centroid_hull_x, gauss, mode='same', method = 'direct') / gauss.sum()\n",
    "    y_gauss = signal.convolve(centroid_hull_y, gauss, mode = 'same', method = 'direct') / gauss.sum()\n",
    "    \n",
    "    new_path = r'C:\\Users\\Daniellab\\Desktop\\Light_level_videos_second_batch\\Data\\Step1_Tanvi_Method'\n",
    "    # new_path = 'C:/Users/tanvid2/Documents/PyCharm Projects/videoAnalysis/OutputData/'\n",
    "    full_path = new_path + \"\\\\\" + name\n",
    "\n",
    "    # collect all the variables I want to save\n",
    "    df1 = pd.DataFrame({'NumPixel': num_pixel})\n",
    "    df2 = pd.DataFrame({'Centroid_basic_x': centroid_basic_x})\n",
    "    df3 = pd.DataFrame({'Centroid_basic_y': centroid_basic_y})\n",
    "    df4 = pd.DataFrame({'Centroid_hull_x': x_gauss})\n",
    "    df5 = pd.DataFrame({'Centroid_hull_y': y_gauss})\n",
    "#    df6 = pd.DataFrame({'Contour_basic': contour_basic})\n",
    "#    df7 = pd.DataFrame({'Contour_hull': contour_hull})\n",
    "\n",
    "    df_entire = pd.concat([df1, df2, df3, df4, df5], axis=1)\n",
    "    df_entire.to_csv(full_path + '.csv')\n",
    "\n",
    "    t1 = time.time()\n",
    "    with open('LogFile.txt', 'a') as log_text:\n",
    "        log_text.write('\\t' + '\\t' + '\\t' + '\\t' + name + '\\t' + str(total_frame) + ' frames took ' + str(t1-t0) + ' seconds' + '\\n')\n",
    "        log_text.write(str(time.asctime()) + '\\t' + name + ' done' + '\\n')\n",
    "\n",
    "    print(name + ' took ' + str(t1-t0) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  9 16:43:44 2019\tExperimental_1 loaded\n",
      "analyzing 190723 frames for Experimental_1\n",
      "Experimental_1 took 1427.1840000152588 seconds\n",
      "Mon Dec  9 17:07:31 2019\tExperimental_2 loaded\n",
      "analyzing 102316 frames for Experimental_2\n",
      "Experimental_2 took 764.0059998035431 seconds\n",
      "Mon Dec  9 17:20:15 2019\tExperimental_3 loaded\n",
      "analyzing 159895 frames for Experimental_3\n",
      "Experimental_3 took 1163.7770001888275 seconds\n",
      "Mon Dec  9 17:39:39 2019\tExperimental_4 loaded\n",
      "analyzing 170735 frames for Experimental_4\n",
      "Experimental_4 took 1240.2070000171661 seconds\n",
      "Mon Dec  9 18:00:19 2019\tExperimental_5 loaded\n",
      "analyzing 131660 frames for Experimental_5\n",
      "Experimental_5 took 957.3170001506805 seconds\n",
      "Mon Dec  9 18:16:17 2019\tExperimental_6 loaded\n",
      "analyzing 92276 frames for Experimental_6\n",
      "Experimental_6 took 682.6659998893738 seconds\n",
      "Mon Dec  9 18:27:39 2019\tExperimental_7 loaded\n",
      "analyzing 171792 frames for Experimental_7\n",
      "Experimental_7 took 1251.3049998283386 seconds\n",
      "Mon Dec  9 18:48:31 2019\tPseudo_1 loaded\n",
      "analyzing 144660 frames for Pseudo_1\n",
      "Pseudo_1 took 1059.1420001983643 seconds\n",
      "Mon Dec  9 19:06:10 2019\tPseudo_2 loaded\n",
      "analyzing 147823 frames for Pseudo_2\n",
      "Pseudo_2 took 1072.5309998989105 seconds\n",
      "Mon Dec  9 19:24:02 2019\tSham_1 loaded\n",
      "analyzing 175187 frames for Sham_1\n",
      "Sham_1 took 1315.3310000896454 seconds\n",
      "Mon Dec  9 19:45:58 2019\tSham_10 loaded\n",
      "analyzing 94239 frames for Sham_10\n",
      "Sham_10 took 696.2919998168945 seconds\n",
      "Mon Dec  9 19:57:34 2019\tSham_11 loaded\n",
      "analyzing 131704 frames for Sham_11\n",
      "Sham_11 took 1009.5009999275208 seconds\n",
      "Mon Dec  9 20:14:23 2019\tSham_12 loaded\n",
      "analyzing 75910 frames for Sham_12\n",
      "Sham_12 took 599.2260000705719 seconds\n",
      "Mon Dec  9 20:24:23 2019\tSham_13 loaded\n",
      "analyzing 100276 frames for Sham_13\n",
      "Sham_13 took 756.2409999370575 seconds\n",
      "Mon Dec  9 20:36:59 2019\tSham_14 loaded\n",
      "analyzing 63177 frames for Sham_14\n",
      "Sham_14 took 463.57100009918213 seconds\n",
      "Mon Dec  9 20:44:42 2019\tSham_15 loaded\n",
      "analyzing 65736 frames for Sham_15\n",
      "Sham_15 took 522.936999797821 seconds\n",
      "Mon Dec  9 20:53:25 2019\tSham_16 loaded\n",
      "analyzing 61606 frames for Sham_16\n",
      "Sham_16 took 476.73400020599365 seconds\n",
      "Mon Dec  9 21:01:22 2019\tSham_17 loaded\n",
      "analyzing 67754 frames for Sham_17\n",
      "Sham_17 took 513.3270001411438 seconds\n",
      "Mon Dec  9 21:09:55 2019\tSham_18 loaded\n",
      "analyzing 78958 frames for Sham_18\n",
      "Sham_18 took 591.0069999694824 seconds\n",
      "Mon Dec  9 21:19:46 2019\tSham_2 loaded\n",
      "analyzing 134541 frames for Sham_2\n",
      "Sham_2 took 993.4249999523163 seconds\n",
      "Mon Dec  9 21:36:20 2019\tSham_3 loaded\n",
      "analyzing 160959 frames for Sham_3\n",
      "Sham_3 took 1198.3940002918243 seconds\n",
      "Mon Dec  9 21:56:18 2019\tSham_4 loaded\n",
      "analyzing 145299 frames for Sham_4\n",
      "Sham_4 took 1093.3940000534058 seconds\n",
      "Mon Dec  9 22:14:32 2019\tSham_5 loaded\n",
      "analyzing 89733 frames for Sham_5\n",
      "Sham_5 took 656.9679999351501 seconds\n",
      "Mon Dec  9 22:25:29 2019\tSham_6 loaded\n",
      "analyzing 163642 frames for Sham_6\n",
      "Sham_6 took 1252.295000076294 seconds\n",
      "Mon Dec  9 22:46:21 2019\tSham_7 loaded\n",
      "analyzing 123457 frames for Sham_7\n",
      "Sham_7 took 901.8410000801086 seconds\n",
      "Mon Dec  9 23:01:23 2019\tSham_8 loaded\n",
      "analyzing 127105 frames for Sham_8\n",
      "Sham_8 took 938.7079999446869 seconds\n",
      "Mon Dec  9 23:17:01 2019\tSham_9 loaded\n",
      "analyzing 85969 frames for Sham_9\n",
      "Sham_9 took 647.8489999771118 seconds\n"
     ]
    }
   ],
   "source": [
    "#load L0.1_c-3_m5 but the cut version\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
