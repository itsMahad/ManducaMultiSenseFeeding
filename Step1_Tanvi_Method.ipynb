{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "# Defining all the functions I use here\n",
    "\n",
    "def erodeImage(image):\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "    erosion = cv2.erode(image, kernel, iterations=1)\n",
    "    return erosion\n",
    "\n",
    "def dilateImage(image):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilate = cv2.dilate(image,kernel, iterations=1)\n",
    "    return dilate\n",
    "\n",
    "# removing high pixels - input single image\n",
    "\n",
    "#def removeHighPixel(image):\n",
    "#    im = np.copy(image)\n",
    "#    im[im > 220] = 0\n",
    "#    return im\n",
    "\n",
    "\n",
    "# calculate total number of pixels above threshold\n",
    "\n",
    "def pixelThreshold(image):\n",
    "    image = np.asarray(image)\n",
    "    val = image[image > 5]\n",
    "    count = len(val)\n",
    "    return count\n",
    "\n",
    "\n",
    "# calculate centroid, Num of pixels > threshold for a single frame\n",
    "\n",
    "def MotionParameters(diff_image):\n",
    "#    high_pix = removeHighPixel(diff_image)\n",
    "    eroded = erodeImage(diff_image)\n",
    "    dilated = dilateImage(eroded)\n",
    "    pixel = pixelThreshold(dilated)\n",
    "\n",
    "    mask = cv2.inRange(dilated, 5, 200)   # extract contour and the centroid of the biggest contour\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    _, contours, hierarchy = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = [cv2.contourArea(c) for c in contours]\n",
    "    if (len(contours) >= 1) & np.any(areas):\n",
    "\n",
    "        max_index = np.argmax(areas)    # Find the index of the largest contour\n",
    "        contour_basic = contours[max_index]\n",
    "        contour_hull = cv2.convexHull(contour_basic)\n",
    "\n",
    "        M = cv2.moments(contour_basic)\n",
    "        centroid_basic = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "        M_hull = cv2.moments(contour_hull)\n",
    "        centroid_hull = (int(M_hull[\"m10\"] / M_hull[\"m00\"]), int(M_hull[\"m01\"] / M_hull[\"m00\"]))\n",
    "\n",
    "    else:\n",
    "        centroid_basic = (np.nan, np.nan)\n",
    "#        contour_basic = ()\n",
    "        centroid_hull = (np.nan, np.nan)\n",
    "#        contour_hull = ()\n",
    "\n",
    "    return pixel, centroid_basic, centroid_hull\n",
    "\n",
    "\n",
    "# make a list of all mp4 files\n",
    "def listOfVideos(path): \n",
    "#path = 'C:/Users/tanvid2/Documents/FLowerMorph-LearningExpt/Videos'\n",
    "# path = 'C:\\\\Users\\\\tanvid2\\\\Documents\\\\PyCharm Projects\\\\videoAnalysis\\\\testLoopVideos'\n",
    "    video_files = [(os.path.join(root, name), name[0:-4])\n",
    "                   for root, dirs, files in os.walk(path)\n",
    "                   for name in files\n",
    "                   if name.endswith('.mp4')]\n",
    "    return video_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Daniellab\\\\Desktop\\\\Light_level_videos_second_batch\\\\Videos\\\\Other_videos\\\\L0.1_c-3_m8.mp4',\n",
       " 'L0.1_c-3_m8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_files[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 25 12:02:20 2019\tL0.1_c-3_m8 loaded\n",
      "analyzing 163986 frames for L0.1_c-3_m8\n",
      "L0.1_c-3_m8 took 1380.8399999141693 seconds\n",
      "Wed Sep 25 12:25:20 2019\tL50_c-3_m10 loaded\n",
      "analyzing 117965 frames for L50_c-3_m10\n",
      "L50_c-3_m10 took 941.2439999580383 seconds\n",
      "Wed Sep 25 12:41:02 2019\tL50_c-3_m12 loaded\n",
      "analyzing 165290 frames for L50_c-3_m12\n",
      "L50_c-3_m12 took 1391.1180002689362 seconds\n",
      "Wed Sep 25 13:04:13 2019\tL50_c-3_m13 loaded\n",
      "analyzing 166870 frames for L50_c-3_m13\n",
      "L50_c-3_m13 took 1341.1870000362396 seconds\n",
      "Wed Sep 25 13:26:34 2019\tL50_c-3_m14 loaded\n",
      "analyzing 140125 frames for L50_c-3_m14\n",
      "L50_c-3_m14 took 1137.281000137329 seconds\n",
      "Wed Sep 25 13:45:31 2019\tL50_c-3_m15 loaded\n",
      "analyzing 148664 frames for L50_c-3_m15\n",
      "L50_c-3_m15 took 1244.587000131607 seconds\n",
      "Wed Sep 25 14:06:16 2019\tL50_c-3_m2 loaded\n",
      "analyzing 120995 frames for L50_c-3_m2\n",
      "L50_c-3_m2 took 954.9130001068115 seconds\n",
      "Wed Sep 25 14:22:11 2019\tL50_c-3_m21 loaded\n",
      "analyzing 186985 frames for L50_c-3_m21\n",
      "L50_c-3_m21 took 1591.0880000591278 seconds\n",
      "Wed Sep 25 14:48:42 2019\tL50_c-3_m22 loaded\n",
      "analyzing 200162 frames for L50_c-3_m22\n",
      "L50_c-3_m22 took 2479.0300002098083 seconds\n",
      "Wed Sep 25 15:30:01 2019\tL50_c-3_m24 loaded\n",
      "analyzing 123194 frames for L50_c-3_m24\n",
      "L50_c-3_m24 took 1220.299000263214 seconds\n",
      "Wed Sep 25 15:50:21 2019\tL50_c-3_m30 loaded\n",
      "analyzing 153704 frames for L50_c-3_m30\n",
      "L50_c-3_m30 took 1333.3330001831055 seconds\n",
      "Wed Sep 25 16:12:35 2019\tL50_c-3_m32 loaded\n",
      "analyzing 211993 frames for L50_c-3_m32\n",
      "L50_c-3_m32 took 3089.7990000247955 seconds\n",
      "Wed Sep 25 17:04:04 2019\tL50_c-3_m33 loaded\n",
      "analyzing 158127 frames for L50_c-3_m33\n",
      "L50_c-3_m33 took 1371.9870002269745 seconds\n",
      "Wed Sep 25 17:26:56 2019\tL50_c-3_m34 loaded\n",
      "analyzing 100275 frames for L50_c-3_m34\n",
      "L50_c-3_m34 took 787.9070000648499 seconds\n",
      "Wed Sep 25 17:40:04 2019\tL50_c-3_m35 loaded\n",
      "analyzing 120463 frames for L50_c-3_m35\n",
      "L50_c-3_m35 took 941.9389998912811 seconds\n",
      "Wed Sep 25 17:55:46 2019\tL50_c-3_m37 loaded\n",
      "analyzing 110109 frames for L50_c-3_m37\n",
      "L50_c-3_m37 took 902.8200001716614 seconds\n",
      "Wed Sep 25 18:10:49 2019\tL50_c-3_m38 loaded\n",
      "analyzing 74572 frames for L50_c-3_m38\n",
      "L50_c-3_m38 took 587.0129997730255 seconds\n",
      "Wed Sep 25 18:20:36 2019\tL50_c-3_m39 loaded\n",
      "analyzing 196535 frames for L50_c-3_m39\n",
      "L50_c-3_m39 took 1634.5539999008179 seconds\n",
      "Wed Sep 25 18:47:51 2019\tL50_c-3_m45 loaded\n",
      "analyzing 168964 frames for L50_c-3_m45\n",
      "L50_c-3_m45 took 1344.0060002803802 seconds\n",
      "Wed Sep 25 19:10:15 2019\tL50_c-3_m6 loaded\n",
      "analyzing 147833 frames for L50_c-3_m6\n",
      "L50_c-3_m6 took 1237.9889998435974 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run analysis through all files\n",
    "\n",
    "#give path to videofiles\n",
    "path = r\"C:\\Users\\Daniellab\\Desktop\\Light_level_videos_second_batch\\Videos\\Other_videos\"    \n",
    "video_files = listOfVideos(path)\n",
    "for file in video_files[18:]:\n",
    "    path = file[0]\n",
    "    name = file[1]\n",
    "    \n",
    "    with open('LogFile.txt', 'a') as log_text:\n",
    "        log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' loaded' + '\\n')\n",
    "    print(str(time.asctime()) + '\\t' + file[1] + ' loaded')\n",
    "\n",
    "    t0 = time.time()     # log the start time\n",
    "\n",
    "    # declare all variables\n",
    "    num_pixel = []\n",
    "    centroid_basic_x = []\n",
    "    centroid_basic_y = []\n",
    "    centroid_hull_x = []\n",
    "    centroid_hull_y = []\n",
    "#    contour_basic = []\n",
    "#    contour_hull = []\n",
    "\n",
    "    cam = cv2.VideoCapture(path)  # load video as object\n",
    "\n",
    "    back_frame = 0  # calculate background to subtract from frame\n",
    "    cam.set(1, back_frame)\n",
    "    ret, f = cam.read(1)  # Read the image at the first frame\n",
    "    if not ret:\n",
    "        with open('LogFile.txt', 'a') as log_text:\n",
    "            log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' first image not read' + '\\n')\n",
    "        print(str(time.asctime()) + '\\t' + name + ' image not read')\n",
    "    background = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # loop through all frames of the video\n",
    "    total_frame = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_seq = list(range(0, total_frame))\n",
    "\n",
    "    print('analyzing ' + str(total_frame) + ' frames for ' + name)\n",
    "\n",
    "    for frame in frame_seq:\n",
    "        cam.set(1, frame)  # start processing the current frame\n",
    "        ret, f = cam.read(1)  # Read the image at that frame\n",
    "        if not ret:\n",
    "            with open('LogFile.txt', 'a') as log_text:\n",
    "                log_text.write('\\n' + str(time.asctime()) + '\\t' + name + ' frame ' + frame + ' not read' + '\\n')\n",
    "            print(str(time.asctime()) + '\\t' + name + ' frame ' + frame + ' not read')\n",
    "        \n",
    "        \n",
    "        img = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        diff_im = cv2.subtract(img, background)\n",
    "        \n",
    "        pixel, cent_b, cent_hull = MotionParameters(diff_im)\n",
    "        num_pixel.append(pixel)\n",
    "        centroid_basic_x.append(cent_b[0])\n",
    "        centroid_basic_y.append(cent_b[1])\n",
    "        centroid_hull_x.append(cent_hull[0])\n",
    "        centroid_hull_y.append(cent_hull[1])\n",
    "#        contour_basic.append(cont_b)\n",
    "#        contour_hull.append(cont_hull)\n",
    "    \n",
    "    gauss = signal.gaussian(3,3)\n",
    "    x_gauss = signal.convolve(centroid_hull_x, gauss, mode='same', method = 'direct') / gauss.sum()\n",
    "    y_gauss = signal.convolve(centroid_hull_y, gauss, mode = 'same', method = 'direct') / gauss.sum()\n",
    "    \n",
    "    new_path = r'C:\\Users\\Daniellab\\Desktop\\Light_level_videos_second_batch\\Data\\Step1_Tanvi_Method'\n",
    "    # new_path = 'C:/Users/tanvid2/Documents/PyCharm Projects/videoAnalysis/OutputData/'\n",
    "    full_path = new_path + \"\\\\\" + name\n",
    "\n",
    "    # collect all the variables I want to save\n",
    "    df1 = pd.DataFrame({'NumPixel': num_pixel})\n",
    "    df2 = pd.DataFrame({'Centroid_basic_x': centroid_basic_x})\n",
    "    df3 = pd.DataFrame({'Centroid_basic_y': centroid_basic_y})\n",
    "    df4 = pd.DataFrame({'Centroid_hull_x': x_gauss})\n",
    "    df5 = pd.DataFrame({'Centroid_hull_y': y_gauss})\n",
    "#    df6 = pd.DataFrame({'Contour_basic': contour_basic})\n",
    "#    df7 = pd.DataFrame({'Contour_hull': contour_hull})\n",
    "\n",
    "    df_entire = pd.concat([df1, df2, df3, df4, df5], axis=1)\n",
    "    df_entire.to_csv(full_path + '.csv')\n",
    "\n",
    "    t1 = time.time()\n",
    "    with open('LogFile.txt', 'a') as log_text:\n",
    "        log_text.write('\\t' + '\\t' + '\\t' + '\\t' + name + '\\t' + str(total_frame) + ' frames took ' + str(t1-t0) + ' seconds' + '\\n')\n",
    "        log_text.write(str(time.asctime()) + '\\t' + name + ' done' + '\\n')\n",
    "\n",
    "    print(name + ' took ' + str(t1-t0) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load L0.1_c-3_m5 but the cut version\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
